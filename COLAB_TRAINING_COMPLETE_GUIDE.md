# üöÄ GOOGLE COLAB TRAINING SETUP GUIDE - Complete Step-by-Step

## Overview

This guide walks you through **everything from scratch** - from opening Google Colab to running your TD3 training on free Google GPU.

**Estimated time:** 15 minutes to complete setup, then training runs automatically.

**Why Colab?**
- ‚úÖ Completely FREE GPU (Tesla K80/T4/P100)
- ‚úÖ No installation needed
- ‚úÖ 12 hours runtime (enough for our 5-hour training)
- ‚úÖ Google Drive integration for saving models

---

## PART 1: Google Colab Setup (2 minutes)

### Step 1.1: Open Google Colab

1. Go to [colab.research.google.com](https://colab.research.google.com)
2. You'll see a dialog: "Open notebook"
3. Click **"+ New notebook"** (bottom right)

### Step 1.2: Enable GPU Acceleration

1. In your new notebook, click **"Runtime"** (top menu)
2. Click **"Change runtime type"**
3. Under "Hardware accelerator", select: **GPU** (any option works: T4, K80, P100)
4. Click **"Save"**

**What happens:**
- ‚úÖ Your notebook now has GPU support
- ‚úÖ Free Tesla GPU allocated
- ‚úÖ Ready for fast training!

### Step 1.3: Verify GPU is Available

**Create first cell and run it:**

```python
import torch
import subprocess

# Check GPU
gpu_available = torch.cuda.is_available()
gpu_name = torch.cuda.get_device_name(0) if gpu_available else "No GPU"

print(f"GPU Available: {gpu_available}")
print(f"GPU Name: {gpu_name}")
print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")

# Alternative check
subprocess.run(['nvidia-smi'])
```

**Expected output:**
```
GPU Available: True
GPU Name: Tesla T4 (or similar)
GPU Memory: 16.00 GB
```

If GPU is not available, go back and check Step 1.2!

---

## PART 2: Install Dependencies (2 minutes)

**Create new cell and run:**

```python
# Install required packages
!pip install -q sai-rl gymnasium numpy torch stable-baselines3 wandb tensorboard

print("‚úì Dependencies installed successfully!")
```

**What gets installed:**
- `sai-rl` - SAI environments for soccer
- `gymnasium` - Environment API
- `torch` - Deep learning framework
- `stable-baselines3` - TD3 algorithm
- `wandb` - Experiment tracking
- `tensorboard` - Training monitoring

This takes about 2-3 minutes. Go grab coffee! ‚òï

---

## PART 3: Clone Repository from GitHub (1 minute)

**Create new cell:**

```python
import os
import subprocess

# Clone the repository
!git clone https://github.com/ArenaX-Labs/booster_soccer_showdown.git

# Verify it worked
if os.path.exists('booster_soccer_showdown'):
    print("‚úì Repository cloned successfully!")
    print("\nDirectory contents:")
    for item in os.listdir('booster_soccer_showdown'):
        print(f"  ‚Ä¢ {item}")
else:
    print("‚úó Clone failed. Try again.")
```

**This downloads:**
- ‚úÖ All training scripts
- ‚úÖ Multi-task environment wrapper
- ‚úÖ Configuration files
- ‚úÖ Pre-trained model

---

## PART 4: Setup Python Path and Imports (1 minute)

**Create new cell:**

```python
import sys
import os

# Add repository to path
sys.path.insert(0, '/content/booster_soccer_showdown/training_scripts')

# Verify imports work
try:
    from train_td3_rl import main
    from multi_task_env import MultiTaskWrapper
    print("‚úì All imports successful!")
except ImportError as e:
    print(f"‚úó Import error: {e}")
    print("Retrying with alternative path...")
    sys.path.insert(0, '/content/booster_soccer_showdown')
```

---

## PART 5: Setup Weights & Biases Logging (Optional - 2 minutes)

W&B is optional but **highly recommended** for monitoring!

### Step 5.1: Create W&B Account (if you don't have one)

1. Go to [wandb.ai](https://wandb.ai)
2. Sign up with Google/GitHub/Email (FREE)
3. Create account
4. Go to [wandb.ai/authorize](https://wandb.ai/authorize) to get your API key

### Step 5.2: Login in Colab

**Create new cell:**

```python
import wandb

# Login to Weights & Biases
wandb.login()
```

**What happens:**
1. Click the link that appears
2. Copy your API key from W&B website
3. Paste it back in the Colab prompt
4. ‚úÖ You're logged in!

**Why W&B?**
- üìä Real-time metric tracking
- üìà Beautiful training plots
- üíæ Automatic metric backup
- üîó Share results with others

---

## PART 6: Setup Output Directories (1 minute)

**Create new cell:**

```python
import os
from pathlib import Path

# Create directories for saving models and checkpoints
os.makedirs('/content/models', exist_ok=True)
os.makedirs('/content/checkpoints', exist_ok=True)

print("‚úì Output directories created:")
print("  ‚Ä¢ /content/models/")
print("  ‚Ä¢ /content/checkpoints/")
print("\nThese will store:")
print("  ‚Ä¢ Final trained model")
print("  ‚Ä¢ Checkpoints (every 5K steps)")
print("  ‚Ä¢ Training results")
```

---

## PART 7: Mount Google Drive (For Saving Models - Optional)

If you want to save models to Google Drive automatically:

**Create new cell:**

```python
from google.colab import drive
import time

# Try to mount Google Drive
try:
    drive.mount('/content/drive')
    print("‚úì Google Drive mounted successfully!")
    
    # Create training folder in Drive
    drive_model_dir = '/content/drive/My Drive/TD3_Soccer_Models'
    os.makedirs(drive_model_dir, exist_ok=True)
    print(f"‚úì Models will be saved to: {drive_model_dir}")
    
except Exception as e:
    print(f"‚ö†Ô∏è Google Drive mount failed: {e}")
    print("\nNo problem! You can still:")
    print("  1. Download files directly from Colab Files panel")
    print("  2. Try mounting again later")
    print("  3. Continue training without Drive (models saved locally)")
```

**If you get credential error:**

1. **Try again in 30 seconds** - Sometimes it's a temporary issue
2. **Restart runtime** - Runtime ‚Üí Restart Runtime ‚Üí Try again
3. **Skip Drive mounting** - Training will still work, just download files manually

This lets you access your trained models from Google Drive after training!

---

## PART 8: THE MAIN EVENT - RUN TRAINING! üöÄ

**Create new cell - this is the one that does everything:**

```python
import sys
import os

# Add to path
sys.path.insert(0, '/content/booster_soccer_showdown/training_scripts')

# Import training function
from train_td3_rl import main

# Configuration class
class Args:
    # ===== ENVIRONMENT =====
    env = "LowerT1GoaliePenaltyKick-v0"  # Primary environment
    second_env = None  # Can add second environment later
    
    # ===== MODEL & DEVICE =====
    device = "cuda"  # Use GPU!
    
    # ===== PRE-TRAINED MODEL =====
    # Path to your pre-trained model (optional)
    pretrained_path = "/content/booster_soccer_showdown/converted_model.pt"
    # If file doesn't exist, training will start from scratch (that's OK!)
    
    # ===== TRAINING HYPERPARAMETERS =====
    timesteps = 5000000  # Total training steps (‚âà 5 hours on GPU)
    batch_size = 256  # Batch size (4x larger for stability)
    learning_rate = 3e-4  # Learning rate (3x baseline)
    buffer_size = 1000000  # Replay buffer size
    learning_starts = 10000  # Steps before learning starts
    
    # ===== TD3 SPECIFIC PARAMETERS =====
    tau = 0.005  # Target network update rate
    gamma = 0.99  # Discount factor
    policy_delay = 2  # Update policy every N critic updates
    
    # ===== CHECKPOINT & LOGGING =====
    checkpoint_interval = 5000  # Save checkpoint every 5K steps ‚úì YOUR REQUIREMENT!
    log_interval = 100  # Log metrics every 100 steps
    
    # ===== OUTPUT PATHS =====
    save_dir = "/content/models"  # Where to save final model
    checkpoint_dir = "/content/checkpoints"  # Where to save checkpoints
    
    # ===== EXPERIMENT TRACKING =====
    use_wandb = True  # Enable W&B logging for monitoring
    

# Print configuration before training
print("=" * 70)
print("üöÄ STARTING TD3 REINFORCEMENT LEARNING TRAINING")
print("=" * 70)
print(f"\nüìä CONFIGURATION:")
print(f"  Environment:          {Args.env}")
print(f"  Device:               {Args.device} (GPU!)")
print(f"  Total timesteps:      {Args.timesteps:,} (‚âà 5 hours)")
print(f"  Batch size:           {Args.batch_size}")
print(f"  Learning rate:        {Args.learning_rate}")
print(f"\nüß† NETWORK ARCHITECTURE:")
print(f"  Policy network:       [512, 256, 128, 64] (DEEP & LARGE!)")
print(f"  Critic network:       [512, 256, 128, 64]")
print(f"  Total parameters:     ~400K (13x larger than baseline)")
print(f"\nüíæ CHECKPOINTING:")
print(f"  Checkpoint interval:  Every {Args.checkpoint_interval:,} steps")
print(f"  Total checkpoints:    ~{Args.timesteps // Args.checkpoint_interval}")
print(f"\nüìà LOGGING:")
print(f"  W&B enabled:          {Args.use_wandb}")
print(f"  Save directory:       {Args.save_dir}")
print(f"  Checkpoint directory: {Args.checkpoint_dir}")
print("\n" + "=" * 70)
print("Starting training in 3 seconds... Press Ctrl+C to cancel")
print("=" * 70 + "\n")

import time
time.sleep(3)

# Create args object
args = Args()

# RUN TRAINING!
try:
    main(args)
    print("\n" + "=" * 70)
    print("‚úÖ TRAINING COMPLETED SUCCESSFULLY!")
    print("=" * 70)
except KeyboardInterrupt:
    print("\n‚ö†Ô∏è Training interrupted by user")
except Exception as e:
    print(f"\n‚ùå Error during training: {e}")
    import traceback
    traceback.print_exc()
```

**What this cell does:**
1. Sets up all hyperparameters
2. Loads the training function
3. Prints configuration for verification
4. **Starts training!** üöÄ
5. Runs for ~5 hours
6. Saves checkpoints every 5K steps
7. Logs everything to W&B (if enabled)

---

## PART 9: Monitor Training Progress (During Training)

### Option A: Watch in W&B Dashboard

If you enabled W&B:

1. Go to [wandb.ai/home](https://wandb.ai/home)
2. Find your run: "td3_rl_YYYYMMDD_HHMMSS"
3. Watch these metrics in real-time:

```
rollout/ep_rew_mean       ‚Üí Episode reward (should go UP! ‚¨ÜÔ∏è)
train/policy_loss         ‚Üí Actor loss (should go DOWN! ‚¨áÔ∏è)
train/value_loss          ‚Üí Critic loss (should go DOWN! ‚¨áÔ∏è)
train/n_updates           ‚Üí Number of updates
```

### Option B: Watch in Colab Console

The training script prints progress every 100 steps:

```
[Time: 0:05:30] Timestep: 10000
[Time: 0:10:15] Timestep: 20000
[Time: 0:15:45] Timestep: 30000
...
```

### What to Expect

```
Hour 0-1: Exploration phase
  Episode reward: -10 to 0
  Loss: Fluctuating
  Behavior: Random or learning basic movements

Hour 1-2: Initial learning
  Episode reward: -5 to +5
  Loss: Decreasing
  Behavior: Starting to improve

Hour 2-3: Good progress
  Episode reward: +5 to +15
  Loss: Continuing to decrease
  Behavior: Clear improvement visible

Hour 3-5: Convergence
  Episode reward: +15 to +25 (or plateau)
  Loss: Stable or slightly improving
  Behavior: Near-optimal or double descent
```

---

## PART 10: Save & Download Results After Training

**Create new cell - run this after training completes:**

```python
import os
import shutil
from datetime import datetime

# Get current timestamp
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# Paths
model_dir = "/content/models"
checkpoint_dir = "/content/checkpoints"

print("=" * 70)
print("üì¶ SAVING AND PREPARING RESULTS FOR DOWNLOAD")
print("=" * 70)

# Copy final model to a unique name
if os.path.exists(f"{model_dir}/td3_final_model.pt"):
    final_model_file = f"{model_dir}/td3_final_model_{timestamp}.pt"
    shutil.copy(
        f"{model_dir}/td3_final_model.pt",
        final_model_file
    )
    print(f"\n‚úÖ Final model saved:")
    print(f"   {final_model_file}")
    file_size = os.path.getsize(final_model_file) / (1024*1024)
    print(f"   Size: {file_size:.2f} MB")
else:
    print("\n‚ö†Ô∏è Final model not found in /content/models/")

# List all checkpoints
print(f"\n‚úÖ Checkpoints saved:")
if os.path.exists(checkpoint_dir):
    checkpoints = sorted(os.listdir(checkpoint_dir))
    total_checkpoints = len(checkpoints)
    print(f"   Total checkpoints: {total_checkpoints}")
    print(f"   Location: {checkpoint_dir}/")
    
    # Show first 5
    for cp in checkpoints[:5]:
        cp_path = os.path.join(checkpoint_dir, cp)
        size = os.path.getsize(cp_path) / (1024*1024)
        print(f"   ‚Ä¢ {cp} ({size:.2f} MB)")
    
    if total_checkpoints > 5:
        print(f"   ... and {total_checkpoints - 5} more checkpoints")
else:
    print(f"   No checkpoints found at {checkpoint_dir}/")

print("\n" + "=" * 70)
print("üì• DOWNLOAD YOUR MODELS")
print("=" * 70)
print("\nYour models are ready in Colab storage:")
print("  1. Click 'Files' icon (left panel)")
print("  2. Navigate to 'models' folder")
print("  3. Click download icon next to files")
print("\nOr if you mounted Google Drive:")
print("  1. Check: /content/drive/My Drive/TD3_Soccer_Models/")
print("  2. Download from Google Drive directly")
print("\n" + "=" * 70)
```

---

## PART 11: Copy Pre-trained Model (If Not Found)

If the pre-trained model wasn't found, you can download it:

**Create new cell:**

```python
import os
import subprocess

# Check if pre-trained model exists
pretrained_path = "/content/booster_soccer_showdown/converted_model.pt"

if not os.path.exists(pretrained_path):
    print("‚ö†Ô∏è Pre-trained model not found")
    print("\nOptions:")
    print("1. Download from your storage and upload to Colab")
    print("2. Train from scratch (still works, but slower convergence)")
    print("\nTo upload:")
    print("  ‚Ä¢ Click Files icon (left)")
    print("  ‚Ä¢ Click upload button")
    print("  ‚Ä¢ Select converted_model.pt")
else:
    size = os.path.getsize(pretrained_path) / (1024*1024)
    print(f"‚úÖ Pre-trained model found!")
    print(f"   Path: {pretrained_path}")
    print(f"   Size: {size:.2f} MB")
```

---

## PART 12: Troubleshooting Common Issues

### Issue: "No GPU available"

**Solution:**
```python
# Go to Runtime ‚Üí Change runtime type ‚Üí GPU
# Then verify:
import torch
print(torch.cuda.is_available())  # Should print True
```

### Issue: "No 'body' with name soccer_ball exists"

**This is a sai_rl version compatibility issue. ‚úÖ FIXED in updated scripts!**

**What was the problem:**
- Different versions of sai_rl use different body naming conventions
- Some use `soccer_ball`, others use `/soccer_ball`
- This mismatch caused the error

**The fix is now BUILT IN:**
- Updated `train_td3_rl.py` - Sets environment variable at startup
- Updated `multi_task_env.py` - Handles body naming compatibility
- **You don't need to do anything extra!** Just run Part 8

**If you still get this error:**

```python
# Make sure you're using the UPDATED scripts from GitHub
# Option 1: Re-clone the repository
!git clone https://github.com/ArenaX-Labs/booster_soccer_showdown.git --force

# Option 2: Manually restart and try again
# Runtime ‚Üí Restart Runtime
# Then run all cells from the top
```

**Why this happened:**
- You were likely using an older version of the scripts
- The new version has the fix built in
- Just pull the latest code and it works!

### Issue: "Module not found: sai_rl"

**Solution:**
```python
# Reinstall with verbose output
!pip install sai-rl --upgrade --verbose

# Or install from source
!pip install git+https://github.com/ArenaX-Labs/sai-rl.git
```

### Issue: "Out of memory" error

**Solution:**
```python
# In Args class, reduce batch size:
batch_size = 128  # Instead of 256

# Or reduce buffer size:
buffer_size = 500000  # Instead of 1000000
```

### Issue: "Pre-trained model not found"

**Solution:**
```python
# Option 1: Don't use pre-trained, train from scratch
args.pretrained_path = None

# Option 2: Upload model file
# Click Files ‚Üí Upload ‚Üí Select converted_model.pt
```

### Issue: "Permission denied" or "Read-only filesystem"

**Solution:**
```python
# Make sure you have write permissions
import os
os.chmod('/content/models', 0o777)
os.chmod('/content/checkpoints', 0o777)
```

### Issue: "Error: credential propagation was unsuccessful" (Google Drive)

**Solution - This is common and easily fixed!**

```python
# Option 1: Try again (often works on second attempt)
from google.colab import drive
import time

try:
    # Wait a moment, then retry
    time.sleep(5)
    drive.mount('/content/drive', force_remount=True)
    print("‚úì Google Drive mounted!")
except:
    print("‚úó Drive mount still failing")
    print("\n‚úì No problem! You can download files directly:")
    print("  1. Click Files icon (left panel)")
    print("  2. Right-click model file")
    print("  3. Click Download")
```

**Option 2: Skip Drive and download manually**
- Training still works fine without Drive
- Just download files from Colab Files panel after training
- No need to mount Drive at all!

**Option 3: Restart and retry**
- Go to Runtime ‚Üí Restart Runtime
- Run the mount cell again
- Usually works on fresh restart

### Issue: Colab keeps disconnecting (after 12 hours)

**Solution - Save before disconnection:**
```python
# If Drive is mounted, manually backup:
import shutil

try:
    # Only do this if Drive is mounted
    shutil.copytree(
        '/content/models',
        '/content/drive/My Drive/TD3_Final_Models',
        dirs_exist_ok=True
    )
    shutil.copytree(
        '/content/checkpoints',
        '/content/drive/My Drive/TD3_Checkpoints',
        dirs_exist_ok=True
    )
    print("‚úì Models backed up to Google Drive!")
except:
    print("‚ö†Ô∏è Backup failed (Drive not mounted)")
    print("‚úì But files are safe in Colab, just download them!")
```

---

## QUICK REFERENCE: All Cells in Order

### Cell 1: Check GPU
```python
import torch
print(f"GPU: {torch.cuda.is_available()}")
print(f"Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")
```

### Cell 2: Install Dependencies
```python
!pip install -q sai-rl gymnasium numpy torch stable-baselines3 wandb tensorboard
print("‚úì Dependencies installed!")
```

### Cell 3: Clone Repository
```python
!git clone https://github.com/ArenaX-Labs/booster_soccer_showdown.git
print("‚úì Repository cloned!")
```

### Cell 4: Setup Path & Imports
```python
import sys
sys.path.insert(0, '/content/booster_soccer_showdown/training_scripts')
from train_td3_rl import main
print("‚úì Imports successful!")
```

### Cell 5: Setup W&B (Optional)
```python
import wandb
wandb.login()
print("‚úì W&B login complete!")
```

### Cell 6: Create Output Directories
```python
import os
os.makedirs('/content/models', exist_ok=True)
os.makedirs('/content/checkpoints', exist_ok=True)
print("‚úì Directories created!")
```

### Cell 7: Mount Google Drive (Optional)
```python
from google.colab import drive
drive.mount('/content/drive')
print("‚úì Google Drive mounted!")
```

### Cell 8: **MAIN - RUN TRAINING!**
```python
import sys
sys.path.insert(0, '/content/booster_soccer_showdown/training_scripts')
from train_td3_rl import main

class Args:
    env = "LowerT1GoaliePenaltyKick-v0"
    second_env = None
    device = "cuda"
    pretrained_path = "/content/booster_soccer_showdown/converted_model.pt"
    timesteps = 5000000
    batch_size = 256
    learning_rate = 3e-4
    buffer_size = 1000000
    learning_starts = 10000
    tau = 0.005
    gamma = 0.99
    policy_delay = 2
    checkpoint_interval = 5000
    log_interval = 100
    save_dir = "/content/models"
    checkpoint_dir = "/content/checkpoints"
    use_wandb = True

args = Args()
print("=" * 70)
print("üöÄ STARTING TD3 TRAINING")
print("=" * 70)
main(args)
```

### Cell 9: Save Results
```python
import os
import shutil
from datetime import datetime

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
model_dir = "/content/models"

if os.path.exists(f"{model_dir}/td3_final_model.pt"):
    shutil.copy(
        f"{model_dir}/td3_final_model.pt",
        f"{model_dir}/td3_final_model_{timestamp}.pt"
    )
    print("‚úì Model saved!")
```

---

## Timeline: Start to Finish

| Time | Action | Duration |
|------|--------|----------|
| 0:00 | Start (read this guide) | - |
| 0:02 | Open Colab & enable GPU | 2 min |
| 0:04 | Run dependency installation | 2 min |
| 0:06 | Clone repository | 1 min |
| 0:08 | Setup path & imports | 1 min |
| 0:10 | Setup W&B (optional) | 2 min |
| 0:12 | Create directories & mount Drive | 2 min |
| 0:15 | **START TRAINING** ‚Üê Cell 8 | 5 hours |
| 5:15 | **TRAINING COMPLETE!** | ‚úÖ |
| 5:17 | Save & download results | 2 min |

**Total: 5 hours 20 minutes from start to trained model!**

---

## What You Get After Training

### Models Saved:
```
‚úÖ td3_final_model_YYYYMMDD_HHMMSS.pt
   ‚îî‚îÄ Your final trained agent
   ‚îî‚îÄ Ready to test or submit

‚úÖ td3_checkpoint_5000_steps.zip
‚úÖ td3_checkpoint_10000_steps.zip
‚úÖ ... (60 total checkpoints)
‚úÖ td3_checkpoint_5000000_steps.zip
   ‚îî‚îÄ Recovery checkpoints every 5K steps
```

### Metrics Tracked:
```
‚úÖ Episode reward (trending UP ‚¨ÜÔ∏è)
‚úÖ Policy loss (trending DOWN ‚¨áÔ∏è)
‚úÖ Critic loss (trending DOWN ‚¨áÔ∏è)
‚úÖ Training progress
‚úÖ Step count
```

### Ready To:
```
‚úÖ Download and test locally
‚úÖ Submit to SAI competition
‚úÖ Fine-tune further
‚úÖ Train on second task
```

---

## After Training: Next Steps

### 1. Download Your Model
- Click Files ‚Üí models folder ‚Üí Download `td3_final_model_*.pt`

### 2. Test Locally
```bash
python test.py --model td3_final_model.pt --env LowerT1GoaliePenaltyKick-v0
```

### 3. Review Metrics
- Go to wandb.ai ‚Üí Find your run ‚Üí Check metrics

### 4. Consider Further Training
- Add second task: `args.second_env = "LowerT1KickToTarget-v0"`
- Add reward shaping (Task 5)
- Train for longer (Task 6)

### 5. Submit to Competition
- Use final model for SAI competition submission

---

## Important Notes

### Colab Runtime Limit

- **Free Tier:** 12 hours per notebook
- **Our training:** 5 hours
- **Margin:** 7 hours extra
- **Note:** If disconnected, you can reconnect and continue with checkpoints!

### GPU Availability

- **Free Tier:** Random GPU (K80, T4, P100)
- **Not guaranteed:** GPU might change between sessions
- **Fallback:** Can run on CPU (slower, but works)

### Pre-trained Model

Your `converted_model.pt` initializes the agent:
- ‚úÖ Faster convergence
- ‚úÖ Better final performance
- ‚úÖ Transfer learning from previous task

If not available:
- ‚úÖ Training starts from scratch (still works)
- ‚úÖ Just takes slightly longer to learn

### Saving to Google Drive

Recommended for long-term storage:
```python
# Mount Drive (Part 7)
drive.mount('/content/drive')

# Models are automatically saved to Drive if you use it
```

---

## Colab vs Kaggle Comparison

| Feature | Colab | Kaggle |
|---------|-------|--------|
| **Cost** | Free | Free |
| **GPU** | Free (K80/T4/P100) | Free (P100) |
| **Runtime** | 12 hours | 9 hours |
| **Setup Time** | 5 min | 10 min |
| **Storage** | 5GB limit | More storage |
| **Drive Integration** | Yes | No |
| **Pre-installed** | Many libraries | Basic |

**Verdict:** Colab is easier and faster to set up!

---

## Debugging: Check Each Step

**After Cell 2 (Dependencies):**
```python
import torch
import sai_rl
print("‚úì All packages installed")
```

**After Cell 3 (Clone):**
```python
import os
assert os.path.exists('booster_soccer_showdown')
print("‚úì Repository cloned")
```

**After Cell 4 (Imports):**
```python
from train_td3_rl import main
from multi_task_env import MultiTaskWrapper
print("‚úì All imports work")
```

**Before Cell 8 (Training):**
```python
# Verify configuration
print(f"Model path exists: {os.path.exists(Args.pretrained_path)}")
print(f"Output dir exists: {os.path.exists(Args.save_dir)}")
print(f"GPU available: {torch.cuda.is_available()}")
```

If any step fails, you'll see the error. Share the error message and I can help!

---

## Summary

You have everything you need:

‚úÖ Google Colab (free, no installation)
‚úÖ GPU support (5-hour training)
‚úÖ All code ready to copy-paste
‚úÖ Pre-trained model loading
‚úÖ Checkpoint saving (every 5K steps)
‚úÖ W&B monitoring (optional)
‚úÖ Complete documentation

**Just follow the cells above and you'll have a trained TD3 agent in 5 hours!**

---

## Questions?

If something doesn't work:

1. **Check error message** - Run the cell again
2. **Check Part 12** - Troubleshooting section
3. **Verify GPU** - Make sure you enabled GPU in Step 1.2
4. **Try restarting** - Runtime ‚Üí Restart Runtime
5. **Start fresh** - Create new Colab notebook and start over

You got this! üöÄ

---

**Last Updated:** December 31, 2025
**Platform:** Google Colab (Free GPU)
**Status:** Ready to train! ‚ú®
